{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import # need it for metaseq import in py27\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, '../JKBio/')\n",
    "import ChIPHelper\n",
    "import itertools\n",
    "import igv\n",
    "import pysam\n",
    "import Datanalytics as da\n",
    "import Helper\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib\n",
    "import bokeh\n",
    "from bokeh.io import output_notebook\n",
    "import multiprocessing\n",
    "processes = multiprocessing.cpu_count()\n",
    "output_notebook()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import ipyparallel as ipp\n",
    "#rc = ipp.Client()\n",
    "#with rc[:].sync_imports():\n",
    "#    import numpy\n",
    "#    import pandas as pd\n",
    "#    import pysam\n",
    "#    import sys\n",
    "#%px sys.path.insert(0, '../JKBio/')\n",
    "#with rc[:].sync_imports():\n",
    "   # import ChIPHelper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build the indexes with bowtie2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bowtie2-build data/reference/reference.fa data/reference/index --threads 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding the data bucket to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcsfuse --only-dir Chip_AML jkobject data/seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extracting which one is single end and paired end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming ill formatted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv mp183-MV411-DMSO-H3K27ac-r1.fastq.gz mp183-MV411-DMSO_H3K27ac-r1.fastq.gz\n",
    "! mv mp718-MV411-IRF2BP2-r9_R1_001.fastq.gz mp718-MV411-IRF2BP2-r9_R1.fastq.gz\n",
    "! mv mp717-MV411-GATA2-r4_R1_001.fastq.gz mp717-MV411-GATA2-r4_R1.fastq.gz\n",
    "! mv mp716-MV411-GSE1-r9_R1_001.fastq.gz mp716-MV411-GSE1-r9_R1.fastq.gz\n",
    "! mv mp715-MV411-ZEB2-r8_R1_001.fastq.gz mp715-MV411-ZEB2-r8_R1.fastq.gz\n",
    "! mv mp714-MV411-ZEB2-r7_R1_001.fastq.gz mp714-MV411-ZEB2-r7_R1.fastq.gz\n",
    "! mv mp702-MV411_DMSO_8h-H3K27ac-r2.fastq.gz mp702-MV411-DMSO_8h_H3K27ac-r2.fastq.gz\n",
    "! mv mp690-MV411_DMSO_8h-MAX-r1.fastq.gz mp690-MV411-DMSO_8h_MAX-r1.fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singlend, paired_end, pairedendict = ChIPHelper.extractPairedSingleEndFrom(folder='data/seqs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'group': [], 'replicate': [], 'fastq_1': [], 'fastq_2': [], 'antibody': [], 'control': []}\n",
    "for rfile in singlend:\n",
    "# should end with r2\n",
    "    dfile = rfile.split('.')[0].split('-')\n",
    "    data['group'].append(dfile[2])\n",
    "    data['antibody'].append('')\n",
    "    data['control'].append('INPUT')\n",
    "    data['replicate'].append(data['group'].count(dfile[2]))\n",
    "    data['fastq_1'].append('data/seqs/' + rfile)\n",
    "    data['fastq_2'].append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data, columns=['group', 'replicate', 'fastq_1', 'fastq_2', 'antibody', 'control']).to_csv('singleend.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlfile=True\n",
    "control = 'INPUT'\n",
    "path_to_fastq = 'data/seqs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'group': [], 'replicate': [], 'fastq_1': [], 'fastq_2': [], 'antibody': [], 'control': []}\n",
    "for file1, file2 in Helper.grouped(paired_end, 2):\n",
    "  # should end with r2\n",
    "    dfile = file1.split('.')[0].split('-')\n",
    "    data['group'].append(dfile[2])\n",
    "    data['antibody'].append('')\n",
    "    data['control'].append(control if control != dfile[2] else '')\n",
    "    data['replicate'].append(dfile[3].split('r')[1][0])\n",
    "    data['fastq_1'].append(path_to_fastq + file1)\n",
    "    data['fastq_2'].append(path_to_fastq + file2)\n",
    "if not controlfile:\n",
    "    raise('we need control file')\n",
    "    pd.DataFrame(data, columns=['group','replicate','fastq_1','fastq_2','antibody','control']).to_csv('design_paired.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'group': [], 'replicate': [], 'fastq_1': [], 'fastq_2': [], 'antibody': [], 'control': []}\n",
    "for file1, file2 in Helper.grouped(paired_end, 2):\n",
    "  # should end with r2\n",
    "    dfile = file1.split('.')[0].split('-')\n",
    "    data['group'].append(dfile[2])\n",
    "    data['antibody'].append('')\n",
    "    data['control'].append(control if control != dfile[2] else '')\n",
    "    data['replicate'].append(dfile[3].split('r')[1][0])\n",
    "    data['fastq_1'].append(path_to_fastq + file1)\n",
    "    data['fastq_2'].append(path_to_fastq + file2)\n",
    "if not controlfile:\n",
    "    raise('we need control file')\n",
    "    pd.DataFrame(data, columns=['group','replicate','fastq_1','fastq_2','antibody','control']).to_csv('design_paired.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChIPHelper.executeNFcore('data/seqs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning and computing peaks \n",
    "\n",
    "We have witnessed some warnings on the data for :\n",
    "\n",
    "- POLII-r1\n",
    "- MEF2D-r1_R1\n",
    "- ZMYND8-r2\n",
    "- GATA2-r4_R1_001\n",
    "\n",
    "and maybe more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paired end\n",
    "CPU = 8\n",
    "ChIPHelper.computeSingleEnd(singlend,CPU = CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChIPHelper.computePairedEnd(pairedendict,CPU = CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChIPHelper.bigWigFrom('data/mapped/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! Rscript data/peaks/mp585-MV411-MYC-r3/NA_model.r\n",
    "from wand.image import Image as WImage\n",
    "img = WImage(filename='NA_model.pdf')\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings = ChIPHelper.loadNarrowPeaks(path='data/peaks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEgenes = pd.read_csv('SEgenes.csv')\n",
    "CTF = pd.read_csv('CTF.csv', header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(bindings.type.tolist())- set(CTF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTF.extend(['GATA2','IKZF1','LYL1' ,'PU1','SMC1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTF = list(set(CTF) - (set(CTF) - set(bindings.type.tolist())))\n",
    "CTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings = bindings.reset_index().drop('index',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = ChIPHelper.mergePeaks(bindings, 1000, TFlist = CTF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones['score'] = zones['score'].values/ np.linalg.norm(zones['score'].values)\n",
    "zones['foldchange'] =  zones['foldchange'].values / np.linalg.norm(zones['foldchange'].values)\n",
    "for val in CTF:\n",
    "    zones[val] = zones[val] / np.linalg.norm(zones[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones[zones.columns[:10]].to_csv('mergepeaks.narrowPeak', sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones.to_csv('saved.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = pd.read_csv('saved.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Helper.plotCorrelationMatrix(zones[zones.columns[11:]].T, names=zones.columns.tolist()[11:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/mapped/\"\n",
    "zones = pd.read_csv('saved.csv',index_col=0)\n",
    "MYC = pysam.AlignmentFile(path+\"mp585-MV411-MYC-r3.bam\", \"rb\")\n",
    "RUNX1= pysam.AlignmentFile(path+\"mp300-MV411-RUNX1-r3_R1.bam\", \"rb\")\n",
    "ZEB2= pysam.AlignmentFile(path+\"mp320-MV411-ZEB2-r1_R1.bam\", \"rb\")\n",
    "SP1= pysam.AlignmentFile(path+\"mp325-MV411-SP1-r2_R1.bam\", \"rb\")\n",
    "MEF2D= pysam.AlignmentFile(path+\"mp324-MV411-MEF2D-r1_R1.bam\", \"rb\")\n",
    "df = zones.sort_values(by=[\"MYC\"],axis=0, ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ChIPHelper.loadNarrowPeaks(\"data/peaks/mp585-MV411-MYC-r3/NA_peaks.narrowPeak\")\n",
    "df = df.sort_values(by=[\"foldchange\"],axis=0, ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[18000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 500\n",
    "CPU = 8\n",
    "#with Pool(CPU) as p:\n",
    "MYC = ChIPHelper.computePeaksAt(df,MYC,2000,20000, window=1000)\n",
    "MEF2D = ChIPHelper.computePeaksAt(df,MEF2D,2000,20000, window=1000)\n",
    "SP1 = ChIPHelper.computePeaksAt(df,SP1,2000,20000, window=1000)\n",
    "RUNX1 = ChIPHelper.computePeaksAt(df,RUNX1,2000,20000, window=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZEB2 = ChIPHelper.computePeaksAt(df,ZEB2,2000,20000, window=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peak Profile accross highest MYC peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normMYC = MYC[np.argsort(MYC.sum(1))[::-1]]\n",
    "normMYC = normMYC / np.max(normMYC,1)[:,None]\n",
    "normMEF2D = MEF2D[np.argsort(MYC.sum(1))[::-1]]\n",
    "normMEF2D = normMEF2D / np.max(normMEF2D,1)[:,None]\n",
    "normSP1 = SP1[np.argsort(MYC.sum(1))[::-1]]\n",
    "normSP1 = normSP1 / np.max(normSP1,1)[:,None]\n",
    "normRUNX1 = RUNX1[np.argsort(MYC.sum(1))[::-1]]\n",
    "normRUNX1 = normRUNX1 / np.max(normRUNX1,1)[:,None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normMYC = normMYC[np.argsort(normMYC.sum(1))[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize = (5,10))\n",
    "plt.box(on=None)\n",
    "plt.axis('off')\n",
    "ax = []\n",
    "TFs = {'MYC':normMYC,'RUNX1':normRUNX1,'SP1':normSP1,'MEF2D':normMEF2D}\n",
    "i = 1\n",
    "cmap = ['Blues','Greens','Purples','Oranges', 'Reds']\n",
    "for key, tf in TFs.iteritems():\n",
    "    ax = [fig.add_subplot(1,len(TFs) , i)]\n",
    "    i+=1\n",
    "    plt.box(on=None)\n",
    "    ax[-1].set_title(key)\n",
    "    ax[-1].axis('off')\n",
    "    plt.imshow(tf, interpolation='nearest', aspect='auto', cmap=cmap[i-1],vmax=1)\n",
    "plt.savefig(\"TFs_MYC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0,1,1,2,3,4,3,0,0,0,0,0]\n",
    "size = 5\n",
    "np.convolve(a, np.ones((size,)) / size, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = zones[zones.columns[11:]]\n",
    "data = np.log2(data.values+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering(n_clusters=2,linkage=\"average\", affinity=\"cosine\", compute_full_tree=True)\n",
    "labels = model.fit_predict(data.T)\n",
    "ii = itertools.count(data.T.shape[0])\n",
    "tree = [{'node_id': next(ii), 'left': x[0], 'right':x[1]} for x in model.children_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Helper.scatter(TSNE(2,5).fit_transform(data.T), labels=zones.columns[11:],colors=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Helper.plotCorrelationMatrix(zones[zones.columns[[11+i for i in labels.argsort()]]].T, names=zones.columns[[11+i for i in labels.argsort()]].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = igv.Browser({\"genome\": \"hg38\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b.load_track({\n",
    "#    \"type\": \"wig\",\n",
    "#    \"format\": \"bigWig\",\n",
    "#    \"name\": \"RUNX1\",\n",
    "#    \"url\": \"data/mapped/mp300-MV411-RUNX1-r3_R1.bw\",\n",
    "#    \"sourceType\":\"file\",\n",
    "#})\n",
    "#b.load_track({\n",
    "#    \"name\": \"RUNX1peaks\",\n",
    "#    \"url\": \"data/peaks/mp300-MV411-RUNX1-r3_R1/NA_peaks.narrowPeak\",\n",
    "#    \"format\": \"narrowPeak\",\n",
    "#    \"type\": \"annotation\",\n",
    "#    \"indexed\": False,\n",
    "#    \"displayMode\": \"COLLAPSED\"\n",
    "#})\n",
    "#b.load_track({\n",
    "#    \"type\": \"wig\",\n",
    "#    \"format\": \"bigWig\",\n",
    "#    \"name\": \"PU1\",\n",
    "#    \"url\": \"data/mapped/mp301-MV411-PU1-r2_R1.bw\",\n",
    "#    \"sourceType\":\"file\",\n",
    "#})\n",
    "#b.load_track({\n",
    "#    \"name\": \"PU1peaks\",\n",
    "#    \"url\": \"data/peaks/mp301-MV411-PU1-r2_R1/NA_peaks.narrowPeak\",\n",
    "#    \"format\": \"narrowPeak\",\n",
    "#    \"type\": \"annotation\",\n",
    "#    \"indexed\": False,\n",
    "#    \"displayMode\": \"COLLAPSED\"\n",
    "#})\n",
    "b.load_track({\n",
    "    \"type\": \"wig\",\n",
    "    \"format\": \"bigWig\",\n",
    "    \"name\": \"MYC\",\n",
    "    \"url\": \"data/mapped/mp301-MV411-PU1-r2_R1.bw\",\n",
    "    \"sourceType\":\"file\",\n",
    "})\n",
    "b.load_track({\n",
    "    \"name\": \"MYCpeaks\",\n",
    "    \"url\": \"data/peaks/mp585-MV411-MYC-r3/NA_peaks.narrowPeak\",\n",
    "    \"format\": \"narrowPeak\",\n",
    "    \"type\": \"annotation\",\n",
    "    \"indexed\": False,\n",
    "    \"displayMode\": \"COLLAPSED\"\n",
    "})\n",
    "b.load_track({\n",
    "    \"name\": \"Mergedpeaks\",\n",
    "    \"url\": \"mergepeaks.narrowPeak\",\n",
    "    \"format\": \"narrowPeak\",\n",
    "    \"type\": \"annotation\",\n",
    "    \"indexed\": False,\n",
    "    \"displayMode\": \"COLLAPSED\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO remove\n",
    "- IgG: basically no binding\n",
    "- DMSO: control substance (MYC?) what is non control?\n",
    "- CTCF, \n",
    "- H3K27ac, \n",
    "- MAX: should be bound at all MYC peaks\n",
    "- POLII: RNA polymerase 2. should be at all transcribed sites (and thus at all chip peaks)\n",
    "- MED1: help POL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minval = np.argsort(np.count_nonzero(data,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What coverage can we achieve with 2, 3 TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxv = 0\n",
    "for i in range(len(minval)):\n",
    "    for j in range(len(minval)):\n",
    "        tot = data[:,j] + data[:,i]\n",
    "        if float(np.count_nonzero(tot)) / data.shape[0] > maxv:\n",
    "            keep = [i,j]\n",
    "            maxv = float(np.count_nonzero(tot)) / data.shape[0]\n",
    "print(maxv,zones.columns[11:][keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxv = 0\n",
    "for i in range(len(minval)):\n",
    "    for j in range(len(minval)):\n",
    "        for k in range(len(minval)):\n",
    "            tot = data[:,k] + data[:,j] + data[:,i]\n",
    "            if float(np.count_nonzero(tot)) / data.shape[0] > maxv:\n",
    "                keep = [i,j,k]\n",
    "                maxv = float(np.count_nonzero(tot)) / data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(maxv,zones.columns[11:][keep])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the best coverage we can achieve with 5 TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(len(minval)):\n",
    "    for m in range(len(minval)):\n",
    "        tot = data[:,keep[0]] + data[:,keep[1]] + data[:,keep[2]] + data[:,l] + data[:,m]\n",
    "        if float(np.count_nonzero(tot)) / data.shape[0] > maxv:\n",
    "            keepadd = [l,m]\n",
    "            maxv = float(np.count_nonzero(tot)) / data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(maxv,zones.columns[11:][keepadd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum of the X most bound TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(np.count_nonzero(np.sum(data[:,minval[-3:]],1))) / data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most globally bound TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones.columns[11:][minval[-6:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "here we have confirmed that POL2 is present at all merged peaks. and that IgG is only present at 0.4% of mergedpeaks. we confirmed that MED1 is present in almost all POL2 merged peaks\n",
    "why IgG and POL2 are very correlated?? should not be the case..\n",
    "\n",
    "\n",
    "CEBPA covers 96% of all tfs, 97% are covered by adding MEF2D and ZEB2. 98.5% by adding IKZF1 and GSE1\n",
    "\n",
    "CEBPA, FLI1, SMC1, MEIS1, IRF8, PU1 together summarize 99.97% of the merged peaks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
