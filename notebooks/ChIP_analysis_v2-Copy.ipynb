{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ChIP AML PiPeline v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "import itertools\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "from JKBio.epigenetics import ChIP_helper as chiphelper\n",
    "from JKBio import Helper as helper\n",
    "\n",
    "import pyBigWig\n",
    "from pybedtools import BedTool\n",
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import IFrame\n",
    "import seaborn as sns\n",
    "from bokeh.plotting import *\n",
    "import igv\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN, KMeans, OPTICS\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.manifold import MDS, TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "output_notebook()\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## adding the data bucket to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "! gcsfuse --only-dir Chip/fastqs amlproject ../data/seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## processing using Nextflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "singleend, pairedend = chiphelper.extractPairedSingleEndFrom('../data/seqs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipeline\n",
    "\n",
    "![](images/gcpjup.png)\n",
    "\n",
    "\n",
    "- Raw read QC (FastQC)\n",
    "- Adapter trimming (Trim Galore!)\n",
    "- Alignment (BWA)\n",
    "- Mark duplicates (picard)\n",
    "- Merge alignments from multiple libraries of the same sample (picard)\n",
    "- Re-mark duplicates (picard)\n",
    "- Filtering to remove: blacklisted regions, duplicates, primary alignments,unmapped,multiple locations, containing >  4 mismatches, insert size > 2kb, map to different chromosomes \n",
    "- Alignment-level QC and estimation of library complexity (picard, Preseq)\n",
    "- Create normalised bigWig files scaled to 1 million mapped reads (BEDTools, bedGraphToBigWig)\n",
    "- Generate gene-body meta-profile from bigWig files (deepTools)\n",
    "- Calculate genome-wide IP enrichment relative to control (deepTools)\n",
    "- Calculate strand cross-correlation peak and ChIP-seq quality measures including NSC and RSC (phantompeakqualtools)\n",
    "- Call broad/narrow peaks (MACS2)\n",
    "- Annotate peaks relative to gene features (HOMER)\n",
    "- Create consensus peakset across all samples and create tabular file to aid in the filtering of the data (BEDTools)\n",
    "- Count reads in consensus peaks (featureCounts)\n",
    "\n",
    "![](images/nfcore.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nextflow cloud create 'JKcluster' -c 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "! nextflow cloud create jkcluster -c \"../nextflow/nextflow.config\" 40 && \\\n",
    "nextflow nf-core/chipseq -c \"../nextflow/nextflow.config\" \\\n",
    "--singleEnd \\\n",
    "--seq_center 'DFCI' \\\n",
    "--email 'jkobject@gmail.com' \\\n",
    "--bucket-dir 'gs://jkobject/Chip_AML/nextflow/CHIPprocess_2/' \\\n",
    "--keyfile '~/jkobject-b6f1adaffcb8.json' \\\n",
    "--projectname 'jkobject' \\\n",
    "--zone 'us-east1-b' \\\n",
    "--skipDiffAnalysis \\\n",
    "--narrowPeak \\\n",
    "--design \"../nextflow/design.csv\" \\ \n",
    "--genome 'GRCh38' \\\n",
    "--profile gcp \\\n",
    "--resume \\\n",
    "--skipPreseq \\\n",
    "--max_cpus 8 && \\\n",
    "nextflow cloud shutdown jkclustert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp -r gs://amlproject/Chip/results/bwa/mergedLibrary/macs/narrowPeak/ ../data/$project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp -r gs://amlproject/Chip/results/bwa/mergedLibrary/bigwig/ ../../data/$project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../../data/narrowPeak/*MV411*.narrowPeak ../data/$project/MV4narrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ../data/BroadPeaks/MV411 && !gsutil -m cp -r gs://amlproject/Chip/results/bwa/mergedLibrary/macs/BroadPeaks/ ../data/$project/ && mv ../../data/$project/BroadPeaks/MV411_* ../data/$project/BroadPeaks/MV411/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings = chiphelper.loadPeaks('../data/MV4narrow/', isMacs=False,skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broadbindings = chiphelper.loadPeaks('../data/BroadPeaks/MV411/', isMacs=False,skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "SEgenes = pd.read_csv('../data/superenhancer/SEgenes.csv')\n",
    "CTF = pd.read_csv('../data/CTF.csv', header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTF.extend(['GATA2','IKZF1','LYL1' ,'PU1','SMC1'])\n",
    "CTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTF = list(set(CTF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = !ls ../data/MV4narrow/*.narrowPeak\n",
    "broadpeaks = ! ls ../data/BroadPeaks/MV411/*.broadPeak\n",
    "peaks = set([i.split('/')[-1].split('.')[0] for i in broadpeaks]) | set([i.split('/')[-1].split('.')[0] for i in peaks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## looking at the data and renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(bindings['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broadbindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings = bindings[~bindings.name.isin(set(broadbindings.name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings = bindings.append(broadbindings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bindings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings['replicate']= [i.split('-')[-1][-1] for i in bindings['name']]\n",
    "bindings['tf'] = [i.split('-')[2] for i in bindings['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings['peak_number'] = ['_'.join([i.split('_')[2],i.split('_')[5]]) for i in bindings['peak_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings.to_csv('../results/'+project+'/bindings.bed',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings= pd.read_csv('../temp/bindings.bed',sep='\\t',header=None, index_col=None,\n",
    "                     names=[\"-log10pvalue\",\"-log10qvalue\", \"chrom\", \"end\", \"foldchange\", \"name\", \"peak_number\", \"relative_summit_pos\", \"start\", \"replicate\",\"tf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsheets import Sheets\n",
    "sheets = Sheets.from_files('~/.client_secret.json', '~/.storage.json')\n",
    "url=\"https://docs.google.com/spreadsheets/d/1yFLjYB1McU530JnLgL0QIMAKIkVl3kl0_LCHje2gk8U\"\n",
    "gsheet = sheets.get(url).sheets[2].to_frame()\n",
    "gsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = ! ls ../../data/bigwig\n",
    "bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(bindings.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE off\n",
    "for i in bw[2:]:\n",
    "    a = gsheet[gsheet.id=='mp'+i.split('_')[2]].name.values[0]\n",
    "    i = '../../data/bigwig/'+i\n",
    "    a = '../../data/bigwig/'+a+'.mLb.clN.bigWig'\n",
    "    ! mv $i $a\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(bindings.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "replicates = chiphelper.findReplicates(folder='data/seqs/results/bwa/', sep='_', namings='_R([0-9])',namepos=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visual inspection of the features and and look at QCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### [igv tracks](https://igv.org/app/?sessionURL=blob:3Z3rU9rcFsb_lU6.vO.Zg0EIcvGbolinYB0vp5czHSeEGFIhscmOaJ3.790hwMbzsrZZ9rTJIx.YAfIk62HxY7Mfcnk0IvfajdzAcY3dR8MfGbvG2Kt1jIoR2FP5nPE2mdrBm7.7Z92x1aqmr_1Lvnhtx8K.POuniwtxG.9Wq7FljhJ7Ip93bswk3nLlIls1057a38PAnsWmE06rvndnDqPQHvlBLHyRCNcMI6_quUE4deNq7H6bb2J.Z843IjfmByP3_o9sTN77coPOgwiHdjD6jdtMN7EvN2GKe2H8qBiT0EliY_e_hj2ZGF8qhojkVtInHg3xcJs2QkqTeZ8qRhiN3MjYlRtvdVrNjlWzGu1m3arttNx_W9tt2bvw_NYPgnQhESXuj8qjkUQTuRIvNfL1Jhx.dR1R7Y7926u9Qb8auXEyEXF1OLOrUzfy3FHfH0Z29FAd.t7M96q9_nHt6qxmTvtD05mcmPLpD773pDdBMpmsSttefX5IpRNOQrmkEXnDv7cr25Vaq51.suyJ6G5.Zez63lgYu5ZcuZ2I8NyxJ3ILqcGKMZOFhLNeEjjCDwMpnrp2IEV3fuwP_YkvHj7Ml5CvbNXk85PQW.ivZUvlCv7nLZMfcX_iPuchDpPIcS.yBqWCFI0wmtqyTCN76.QziwZmD9LKY1U5qzWBHUXh7NS1b5YNubqVD2JTvUC3pLZqyV9T28mEf_1KH.pP.7B4H__RCCdMAqHpRI43fpNL7VufLZmq1NtvB0Eo7HlRFWNq35.FM8nXzrZ0IeXCjdJ1zRF0xlE4DWMJrFxSkusaX36doKMej6D6ql2kEogg0kNxBC1KYhBkARKkcYlG0PHJ6eUFB6HGql.0FIgh2sQfhmhjdwaHvfoBpzs7q.7QUqDu0CaK.4pb1sT4jmsCfsfpbKJ9yZ1esn4ltFbtooRACFEWigMoq4iBTzr3QsOHNokGz_kpC56amhJRSiB6KAvF0ZNVxJmiqkkPDj60SzR8Ph_u11n8qAkRKQUCiPRQHEGLkjgIqUkPDkIam2gMdQ_3T_dYEKl5EK0Foog2URxGy5o4HCFOhHQ.QUGq5wdJzYVoLR5IG0wUDlKdAxLilEjnEw6ki26PNSB1FEeUFAkjykOBFGUlMSBKP_J4ENE20Rg6GJy_v2qPr95a7.ot.f5z_sdTIUOetQCRlcdOcZD9szoOb4hBRD7HqOgN9j6ysFPZxHNrAESOslI8blllHNQQA4vn3UJi9pLhTcUXz64CDbQSD2wvG9UQM40cdtFYO.z3WDl7XSUbpBSILdJDcUwtSuKwhBhraGxiMpQ_HayrVIOUwjFUqmxwURJnf0rEVENjE46hi_80OeOQpaIMUorEEOWhQIaykjgMISYVGpuYDOUfhyyVS5BSOIbKNQ5lJXEYQowgNDYxGbLyM6QyB1IKx9AGD0UzZHEYQswWNDbhDi_bu9hjhQqWChVoLdIRZqSJAg8xW9TE4QgxV9D5BAWJ8YtOJQu0Fg.kUv2mW9bEAKmBGC7ofMKBdH7IOhqjodIFUoqEEeWhQIqykjgQIaYLGpuYDOUfixoqXSClcAyVayTKSuIwhJguaGyiMfSCnRoaKmB4JfszlHNXhhftxdBATBpe1w4Mx0dHLJxU1EApkU7DQVgoDqOsIg5CiCED7RIOn3efe7ypkYoYaC0SQqSJAiFa1MTAaAcxYtD5BAUp__xoR2UMtBYPpFLNkJY1cUBCjBl0PuFAOuvV909Z_x_tqKhBp0aCSWOjQJxWVXGAQswc9E5hkWKMTip20KkRkSrXCLWqioMUYuygdwqLVP5dhXbWogeNGhGpUu0wpKriIAUZQ2idwiLVyI_UWhihUSMitcFGCZBqcE7fChlJaJ0CItXmTKSaa5kEJcWCabOHQklKS.JgBBlI0DbRGOoP3rPCiKYKI0gpEEOkh.IYWpTEYQgxg9DYxGQof_rQVOkDKYVjqFS5w6IkDkOIoYPGJhxDn_qsP2qbKm4gpUgMUR4KZCgricMQYsqgsYnGEPPEXU0VL7yCE3aV70Rd7BN0tRAjhddzYq7B4QHvijAqTiClUJdVIjwUeVWleUkchBDjBI1NPIZ69S4LIpUn0Fqwi5NtNlHsxcnSmjgcIUYKOp.gIOUPFVpPr_K3WYsHUqlihWVNHJBQL_NH.QQFKf.ODC2VLNBaPJBKtRPDsiYOSIjhgs4nHkjH57z50Vq.QGqhQKJMFAlSVhPnwpmQKYPGJxxIn_Y5GLXXYgZCiQQRYaFAhOYVcQCCzBhIl5D45J8XtdcCBkKJhk.55kTzijj4QEYLpEs8fFj5XHstViCUUPiULpubV8TBBzJQIF1C4sMYfdbCBEKJhk_JRh9mHteGjBFIl2j4nL7vHx.zxh8VItBaIIRoE8VBtKyJgVEHMUTQ.UQD6ezy5CMrjeuoGIHWAoFEmygOpGVNHJAQwwSdT0SQWEdAdFSgQGvBQCrbMRDLmjggIcYKOp9oIJ0PurwBSSULpBQII9JDcRQtSuJAhBguaGyiMfT5cJ91JFFHxQukFIgh0kNxDC1K4jCEmDBobMIxNPh0csA6LryjMgaNGIkj2kWBJC2LYrBUSz80eDDpnKLilH9Qqm2rqEGjBuTpt41My.mAex27394cydbF6.uJ3Ot5OyuLXo6FuE3bGVvmKJHlC9u5MZN4y7VjsVUz7an9PQzsWWw64bTqe3dmGHmmXIP8ZMTVsVfryLZfp1sx4zAS7sgU98L0vj9p6e_aiCmG_sa.bMlPTeROwzt7uNYW9UWQ3vRtokxt6tH_Ba4vP34C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### [multiQC](http://35.184.213.1:8888/view/data/results/multiqc/multiqc_report.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### process: \n",
    "\n",
    "look at all t with a very low frip score as noted by encode. \n",
    "\n",
    "look at all peaks tracks together and see for location of intense co binding. \n",
    "\n",
    "- if we can discern peaks and if, for some reasons, some good peaks are not called by macs. \n",
    "- if looks good and we can see a lot of peaks. \n",
    "- if a lot of noise but seems consistent with replicates. \n",
    "- if just seems to have very few peaks.\n",
    "\n",
    "Validate still but flag as potentially bad.\n",
    "\n",
    "Else remove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bad=[\n",
    "\"mp168\",\n",
    "\"mp129\",\n",
    "\"mp128\",\n",
    "\"mp773\",\n",
    "\"mp774\",\n",
    "\"mp575\",\n",
    "\"mp614\",\n",
    "\"mp714\",\n",
    "\"mp433\",\n",
    "\"mp156\",\n",
    "\"mp650\",\n",
    "\"mp604\",\n",
    "\"mp27\",\n",
    "\"mp627\",\n",
    "\"mp117\",\n",
    "\"mp771\",\n",
    "\"mp118\",\n",
    "\"mp431\",\n",
    "\"mp430\",\n",
    "\"mp324\",\n",
    "\"mp565\",\n",
    "\"mp569\",\n",
    "\"mp125\",\n",
    "\"mp627\",\n",
    "\"mp568\",\n",
    "\"mp427\",\n",
    "\"mp124\",\n",
    "\"mp716\",\n",
    "\"mp581\",\n",
    "\"mp589\",\n",
    "\"mp321\",\n",
    "\"mp601\",\n",
    "\"mp745\",\n",
    "\"mp772\",\n",
    "\"mp770\",\n",
    "\"mp590\",\n",
    "\"mp623\",\n",
    "\"mp718\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## merging duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mergedpeak, tomergebam, remove, ratiosofunique = chiphelper.mergeReplicatePeaks(bindings,'../../data/bigwig/',markedasbad=bad, window=150, mincov=4, doPlot=True, minKL=10, cov={}, use='poisson', MINOVERLAP=0.25,lookeverywhere=True, only='',saveloc='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomergebam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedpeak = mergedpeak[mergedpeak.columns[[2,9,3,5,6,4,0,1,7,10]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedpeak.to_csv('../temp/merged_replicates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedpeak = pd.read_csv('../temp/merged_replicates.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show replicates overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sorting and removing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigwigs=os.listdir('../../data/bigwig/')\n",
    "for val in bigwigs:\n",
    "    for v in remove + toremove + ['scale','POLII','IGG','CTCF','INPUT']:\n",
    "        if v in val:\n",
    "            bigwigs.remove(val)\n",
    "            break\n",
    "bigwigs = ['data/bigwig/'+ i for i in bigwigs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(mergedpeak.tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedpeak.foldchange.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedpeak['name']=mergedpeak.tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing bad ChIP protein\n",
    "mergedpeak = mergedpeak[~mergedpeak['name'].isin(['CDK13','GSE1'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a consensus set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = chiphelper.simpleMergePeaks(mergedpeak[~mergedpeak.tf.isin(['MED1','SMC1','CTCF','POLII','IRF2BP2_FLAG','IRF2BP2', 'H3K27ac', 'H3K27me3', 'H3K4me3', 'H3K79me2',])], window=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mergedpeak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('../temp/merged.bed', sep='\\t',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv('../temp/merged.bed', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.pairplot(merged[merged.columns[8:14]], corner=True, diag_kind=\"kde\", kind=\"reg\", plot_kws ={\"scatter_kws\":{\"alpha\":.05}})\n",
    "def col_nan_scatter(x,y, **kwargs):\n",
    "    df = pd.DataFrame({'x':x[:],'y':y[:]})\n",
    "    df = df[df.sum(0)!=0]\n",
    "    x = df['x']\n",
    "    y = df['y']\n",
    "    plt.gca()\n",
    "    plt.scatter(x,y)\n",
    "def col_nan_kde_histo(x, **kwargs):\n",
    "    df = pd.DataFrame({'x':x[:]})\n",
    "    df = df[df['x']!=0]\n",
    "    x = df['x']\n",
    "    plt.gca()\n",
    "    sns.kdeplot(x)\n",
    "fig = fig.map_upper(col_nan_scatter)\n",
    "fig = fig.map_upper(col_nan_kde_histo)\n",
    "fig.savefig('../results/cobinding/pairplot_experiments.pdf')\n",
    "plt.show()\n",
    "counts,val = np.unique(merged[merged.columns[8:]].astype(bool).sum(1).values, return_counts=True)\n",
    "fig = sns.barplot(data=pd.DataFrame(val, index=counts,columns=['counts']).T).set_yscale(\"log\")\n",
    "fig.savefig('../results/cobinding/pairplot_experiments.pdf')\n",
    "plt.show()\n",
    "i = merged[merged.columns[8:]].astype(bool).sum(1)\n",
    "print(i.max(),i.mean(),i.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts,val = np.unique(merged[merged.columns[8:]].astype(bool).sum(1).values, return_counts=True)\n",
    "fig = sns.barplot(data=pd.DataFrame(val, index=counts,columns=['counts']).T).set_yscale(\"log\")\n",
    "fig.savefig(\"../results/cobinding/cobinding_distribution.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random distribution compare\n",
    "\n",
    "### computation:\n",
    "\n",
    "we are evalutating each event's probability 1 binding, 2 binding, n binding.., as a binomial over the amount of proability p_i with n retries corresponding to the size of the conscensus peak set.\n",
    "the probability p_i of this binomial is the sum of probabilities of having tf a binding with b for all possible combination of tf. \n",
    "the number of combination is k amongst n, n being 33, k going from 1 to 29\n",
    "we compute \n",
    "\n",
    "$p(a & b) = p(a)\\*p(b) =p(ab)$\n",
    "\n",
    "and \n",
    "\n",
    "$p(a & b) | p(a & c) = p(ab) + p(ac) - p(abc)$\n",
    "\n",
    "for a,b,c,d:\n",
    "\n",
    "$p(ab) + p(ac) + p(ad) + p(bc) + p(bd) + p(cd) - {3\\choose 2}*(p(abc) - p(abd) - p(bcd) - p(acd)) - {4\\choose 2}*p(abcd)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = merged[merged.columns[8:]].astype(bool).sum(0)/len(merged)\n",
    "sums = {i:0 for i in range(1,30)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sums = {i:0 for i in range(1,30)}\n",
    "for i in range(29,0,-1):\n",
    "    print(i)\n",
    "    if sums[i]> 0:\n",
    "        continue\n",
    "    print(helper.combin(33,i))\n",
    "    for j in itertools.combinations(proba, i):\n",
    "        sums[i]+=np.prod(j) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = helper.fileToDict('sums.json')\n",
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(29,0,-1):\n",
    "    for j in range(i+1,30):\n",
    "        icomb = helper.combin(j,i)\n",
    "        sums[str(i)] -= icomb*sums[str(j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "for i in range(29,0,-1):\n",
    "    print(i,binom.mean(len(merged), sums[str(i)]),binom.var(len(merged), sums[str(i)]))\n",
    "    sums[str(i)] = [binom.mean(len(merged), sums[str(i)]),binom.var(len(merged), sums[str(i)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(sums).T.rename(columns={0:'mean',1:'var'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[merged.columns[8:]].astype(bool).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(val*counts).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int((data['mean'] * data.index.astype(int)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.barplot(data=data.T).set_yscale(\"log\")\n",
    "fig.savefig(\"../results/cobinding/expected_cobinding_distribution.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res['change']=val/data['mean']\n",
    "res['count']=list(res.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.barplot(data=res.T).set_yscale(\"log\")\n",
    "fig.savefig(\"../results/cobinding/cobinding_enrichment.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.bar(res['count'],res['change'],log=True)\n",
    "fig.savefig(\"../results/cobinding/correlation_onoverlap.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.bar(ares['count'],ares['change'],log=True)\n",
    "fig.savefig(\"../results/cobinding/cobinding_enrichment_zoomed.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation over consensus set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(np.corrcoef(stats.zscore(merged[merged.columns[8:]].values.T, axis=1)), figsize=(20, 20), xticklabels=merged.columns[8:], yticklabels=merged.columns[8:]).ax_col_dendrogram.set_visible(False)\n",
    "fig.savefig(\"../results/cobinding/correlation_cobinding_regular.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[merged.columns[:8]].to_csv('../temp/conscensus.bed',sep='\\t',index=None, columns=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## annotatePeaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional = {}\n",
    "additional['activation'] = chiphelper.simpleMergePeaks(mergedpeak[mergedpeak.tf.isin([\"H3K27ac\",'H3K79me2','H3K36me3','H3K4me3'])], window=10, mergedFold=\"max\")\n",
    "additional['repression'] = mergedpeak[mergedpeak.tf=='H3K27me3']\n",
    "additional['IRF2BP2'] = mergedpeak[mergedpeak.tf=='IRF2BP2_FLAG']\n",
    "additional['MED1'] = mergedpeak[mergedpeak.tf=='MED1']\n",
    "additional['SMC1'] = mergedpeak[mergedpeak.tf=='SMC1']\n",
    "additional['CTCF'] = mergedpeak[mergedpeak.tf=='CTCF']\n",
    "additional['POLII'] = mergedpeak[mergedpeak.tf=='POLII']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in additional.items():\n",
    "    merged[key] = chiphelper.putInConscensus(merged[merged.columns[:8]],val)\n",
    "    merged = merged.replace(np.nan,0)\n",
    "    merged[key].astype(bool).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding ATACseq\n",
    "ATAC= chiphelper.loadPeaks(peakFile='../../data/ATACseq/ATAC_MV411.mRp.clN_peaks.broadPeak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ATAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['ATAC'] = chiphelper.putInConscensus(merged[merged.columns[:8]],ATAC)\n",
    "merged = merged.replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['ATAC'].astype(bool).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute enhancers at TSS in the matrix (promoters)\n",
    "promoters = pd.read_csv('../data/human_epdnew_TeLy2.bed', sep='\\t',header=None).rename(columns={0:'chrom',1:'start',2:'end',3:'name',5:'strand'}).drop(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoters['foldchange']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoters['name']=[i[:-2] for i in promoters['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['promoters'] = chiphelper.putInConscensus(merged[merged.columns[:8]],promoters)\n",
    "merged = merged.replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['promoters'].astype(bool).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add super enhancers and compute other enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(bindings[bindings.tf==\"H3K27ac\"].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ../../data/MV411_H3K27ac\n",
    "! cp ../../data/MV4narrow/mp70-MV411-H3K27ac-r2.narrowPeak ../../data/MV411_H3K27ac\n",
    "! cp ../../data/MV4narrow/mp734-MV411_DMSO-H3K27ac-r1.narrowPeak ../../data/MV411_H3K27ac\n",
    "! cp ../../data/BroadPeaks/MV411/mp88-MV411-H3K27ac-r3.broadPeak ../../data/MV411_H3K27ac\n",
    "! cp ../../data/BroadPeaks/MV411/mp702-MV411_DMSO-H3K27ac-r1.broadPeak ../../data/MV411_H3K27ac\n",
    "! cp ../../data/BroadPeaks/MV411/mp183-MV411_DMSO-H3K27ac-r1.broadPeak ../../data/MV411_H3K27ac\n",
    "! cp ../../data/BroadPeaks/MV411/mp136-MV411-H3K27ac-r1.broadPeak ../../data/MV411_H3K27ac\n",
    "! gsutil cp gs://amlproject/Chip/results/bwa/mergedLibrary/*MV411*H3K27* MV411_H3K27ac/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = [\n",
    "\"../../data/MV411_H3K27ac/mp70-MV411-H3K27ac-r2.narrowPeak\",\n",
    "\"../../data/MV411_H3K27ac/mp734-MV411_DMSO-H3K27ac-r1.narrowPeak\",\n",
    "\"../../data/MV411_H3K27ac/mp88-MV411-H3K27ac-r3.broadPeak\",\n",
    "\"../../data/MV411_H3K27ac/mp702-MV411_DMSO-H3K27ac-r1.broadPeak\",\n",
    "\"../../data/MV411_H3K27ac/mp183-MV411_DMSO-H3K27ac-r1.broadPeak\",\n",
    "\"../../data/MV411_H3K27ac/mp136-MV411-H3K27ac-r1.broadPeak\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in peaks:\n",
    "    valbed = val +\".bed\"\n",
    "    ! mv $val $valbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for peak in peaks[1:]:\n",
    "    chiphelper.MakeSuperEnhancers(peak+'.bed',\n",
    "                             bamFile='.'.join(peak.split('.')[:-1])+'.mLb.clN.sorted.bam',\n",
    "                             baiFile='.'.join(peak.split('.')[:-1])+'.mLb.clN.sorted.bam.bai',\n",
    "                             controlBam= '../../data/diffBinding_hist/INPUT_R1.mLb.clN.sorted.bam',\n",
    "                             controlBai= '../../data/diffBinding_hist/INPUT_R1.mLb.clN.sorted.bam.bai',\n",
    "                             outdir ='~/data/MV411_H3K27ac',\n",
    "                             rosePath=\"../src/ROSE/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm ~/data/MV411_H3K27ac/*.bam*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading and merging\n",
    "! mkdir ../results/ROSE/MV411/\n",
    "! cp ~/data/MV411_H3K27ac/*.txt ../results/ROSE/MV411/\n",
    "! cp ~/data/MV411_H3K27ac/*.bed ../results/ROSE/MV411/\n",
    "! cp ~/data/MV411_H3K27ac/*.png ../results/ROSE/MV411/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rose = chiphelper.ReadRoseSuperEnhancers(\"../results/ROSE/MV411/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rose = chiphelper.simpleMergePeaks(rose,window=1000).drop(columns=[\"relative_summit_pos\",\"-log10pvalue\",\"-log10qvalue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rose = rose[rose[rose.columns[5:]].astype(bool).sum(1)>1]\n",
    "rose = rose.sort_values(by=['chrom','start','end']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['super_enhancer'] = chiphelper.putInConscensus(merged[merged.columns[:8]],rose)\n",
    "merged = merged.replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['super_enhancer'].astype(bool).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading super enhancer from max's files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## making regulat enhancers merged[\"regular_enhancers\"]\n",
    "merged['regular_enhancer'] = (merged['activation'].astype(bool) & ~merged[['super_enhancer','promoters']].astype(bool).sum(1).astype(bool)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(mergedpeak.tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['H3K27ac','ATAC','H3K27me3','SMC1',\"POLII\",\"MED1\",\"H3K79me2\",\"H3K4me3\",\"CTCF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['H3K27ac', 'ATAC', 'H3K27me3', 'SMC1', \"POLII\", \"MED1\", \"H3K79me2\", \"H3K4me3\", \"CTCF\", 'CEBPA',\"PU1_FLAG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp ../temp/MV411Merged/ATAC.bed ../../data/ATACseq/ATAC_MV411.mRp.clN_peaks.broadPeak "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mkdir ../temp/MV411Merged\n",
    "for i in set(mergedpeak.tf):\n",
    "    a = mergedpeak[mergedpeak.tf==i][['chrom','start',\"end\",'peak_number',\"foldchange\"]]\n",
    "    a['strand']='+'\n",
    "    a.to_csv(\"../temp/MV411Merged/\"+i+'.bed', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ATAC[['chrom','start',\"end\",\"peak_number\",'foldchange']]\n",
    "a['strand'] = '+'\n",
    "a.to_csv('../temp/MV411Merged/ATAC.bed',index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## computing CHROMHMM\n",
    "#!mkdir ../data/chromHMM/\n",
    "chrombed = chiphelper.runChromHMM(numstates=8, outdir='~/AMLproject/data/chromHMM/', data=pd.DataFrame([['MV411']*len(l),l,[\"AMLproject/temp/MV411Merged/\"+i+'.bed' for i in l]]).T, datatype='bed', folderPath=\"~/\", chromHMMFolderpath=\"../src/ChromHMM/\", control_bam_dir=None)['MV411']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrombed = pd.read_csv('~/AMLproject/data/chromHMM/MV411_8_dense.bed',sep='\\t',header=None, skiprows=1).drop(columns=[4,5,6,7]).rename(columns={0:'chrom',1:'start',2:'end',3:'state',8:\"color\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statetocol={i: chrombed[chrombed['state']==i].iloc[0]['color'] for i in set(chrombed['state'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrombed['foldchange']= chrombed['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['HMM_states'] = chiphelper.putInConscensus(merged[merged.columns[:8]],chrombed,window=1,mergetype='first')\n",
    "merged = merged.replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['regular_enhancer'] = merged['regular_enhancer'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('../temp/merged.bed', sep='\\t',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv('../temp/merged.bed', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Co Binding Matrix\n",
    "\n",
    "Look at AUC for all ChIPs over all peaks of all ChIPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statetocol.update({0:'0,0,0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,v in statetocol.items():\n",
    "    statetocol[i] = tuple([int(i)/256 for i in v.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = np.random.choice(merged.index,5000)\n",
    "viridis = cm.get_cmap('viridis', 256)\n",
    "data = merged[merged.columns[-12:]]\n",
    "for val in data.columns[:-4]:\n",
    "    data[val] =stats.zscore(np.log2(1+data[val]))\n",
    "    data[val] = (((data[val] -data[val].min())/ (data[val].max()))*256).astype(int)\n",
    "#print(data['HMM_states'])\n",
    "data = data.loc[rand]\n",
    "for val in data.columns[:-1]:\n",
    "    a = [viridis(v) for v in data[val]]\n",
    "    data[val] = a\n",
    "data['HMM_states'] = [statetocol[i] for i in data['HMM_states']]\n",
    "data = data.rename(columns={'SMC1':'cohesin','MED1':'mediator','ATAC':'open regions'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.clustermap(np.log2(1.01+merged[merged.columns[8:-12]].loc[rand].T),col_cluster=False, z_score=0, vmin=0,vmax=3, col_colors = data, figsize=(30,20),xticklabels=False)\n",
    "fig.ax_col_dendrogram.set_visible(False)\n",
    "fig.savefig('../temp/clustermap_cobinding_scaled_marks.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.clustermap(np.log2(1.01+merged[merged.columns[8:-12]].loc[rand].T), vmin=0,vmax=3,figsize=(20,15),z_score=0,col_colors=data, xticklabels=False)\n",
    "fig.ax_col_dendrogram.set_visible(False)\n",
    "fig.savefig('../temp/clustermap_cobinding_scaled_marks.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## clustering\n",
    "\n",
    "I have tried gaussian mixtures and Agglomerative clustering algorithm. Only the second can create a hierarchical clustering.\n",
    "\n",
    "It seems that gaussian mixture makes more sense given the data we have, for now, is more \"homogeneous\". \n",
    "\n",
    "**I am still not so happy with the clustering.** It can be because of the how much importance, outlier values and the high number of noisy values from locations with no peaks.\n",
    "\n",
    "We can use similar methods to RNAseq to improve this (clamping values, log transform, first round of PCA..)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "labels = DBSCAN(n_components=2, covariance_type='diag').fit_predict(subcor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "names = np.array([i.split('.')[-4].split('/')[-1] for i in bigwigs])\n",
    "sort = labels.argsort()\n",
    "p = helper.plotCorrelationMatrix(data=cor[sort],\n",
    "                            names=names[sort],\n",
    "                            colors=labels[sort],\n",
    "                            title=\"correlation between TF occupancy\",\n",
    "                            interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = helper.scatter(TSNE(2,5).fit_transform(subcor),labels=names, colors=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(subcor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at peak overlap \n",
    "\n",
    "How many of peak in A (column) overlaps with peak in B (rows)\n",
    "\n",
    "in other words:\n",
    "\n",
    "what is the percentage of B's peaks that are overlaped by A's peaks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[merged.columns[8:]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(stats.zscore(0.01+merged[merged.columns[8:]]).T, columns=merged.index, index=merged.columns[8:])\n",
    "link = linkage(data[:-11])\n",
    "col = data[-11:]\n",
    "col = col[[co for co in col.columns if co not in col.index.tolist()]]\n",
    "for val in col.columns:\n",
    "    col[val] = [viridis(v) for v in col[val]]\n",
    "fig = sns.clustermap(np.corrcoef(data.iloc[:-11])[data.columns[np.concatenate((leaves_list(link),[26,27,28,29,30,31,32,33,34,35,36]))]], row_linkage=link, col_colors=col.T, col_cluster=False)\n",
    "fig.ax_col_dendrogram.set_visible(False)\n",
    "fig.savefig('../results/cobinding/correlation_with_annotation.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap, correlation,_ = chiphelper.computePairwiseOverlap(merged, norm=True,enrichment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data=overlap,index=merged.columns[8:], columns=merged.columns[8:])\n",
    "link = linkage(data.iloc[:-11]) # D being the measurement\n",
    "col = data[-11:]\n",
    "col = col[[co for co in col.columns if co not in col.index.tolist()]]\n",
    "for val in col.columns:\n",
    "    a = [viridis(v) for v in col[val]]\n",
    "    col[val] = a\n",
    "fig = sns.clustermap(data.iloc[:-11][data.columns[np.concatenate((leaves_list(link),[26,27,28,29,30,31,32,33,34,35,36]))]], row_linkage=link, col_colors=col.T, col_cluster=False,figsize=(12,12))\n",
    "fig.ax_col_dendrogram.set_visible(False)\n",
    "fig.savefig('../results/cobinding/overlap.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data on the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([merged[merged.columns[8:]].astype(bool).sum(0),\n",
    "           merged[merged.columns[8:]].max(),\n",
    "           merged[merged.columns[8:]].replace(0, np.NaN).mean(),\n",
    "          merged[merged.columns[8:]].replace(0, np.NaN).var()],axis=1).rename(columns={0:'sum',1:'max',2:'mean',3:'std'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation only on overlaps \n",
    "\n",
    "on the overlaps given above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data=correlation,index=merged.columns[8:], columns=merged.columns[8:])\n",
    "link = linkage(data.iloc[:-11]) # D being the measurement\n",
    "col = data.iloc[-11:]\n",
    "col = col[[co for co in col.columns if co not in col.index.tolist()]]\n",
    "for val in col.columns:\n",
    "    a = [viridis(v) for v in col[val]]\n",
    "    col[val] = a\n",
    "fig = sns.clustermap(data.iloc[:-11][data.columns[np.concatenate((leaves_list(link),[26,27,28,29,30,31,32,33,34,35,36]))]], row_linkage=link, col_colors=col.T, col_cluster=False)\n",
    "fig.ax_col_dendrogram.set_visible(False)\n",
    "fig.savefig(\"../results/cobinding/correlation_onoverlap.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data=np.corrcoef(stats.zscore(merged[merged.columns[8:]]).T), index=merged.columns[8:], columns=merged.columns[8:])\n",
    "link = linkage(data.iloc[:-11]) # D being the measurement\n",
    "col = data.iloc[-11:]\n",
    "col = col[[co for co in col.columns if co not in col.index.tolist()]]\n",
    "for val in col.columns:\n",
    "    a = [viridis(v) for v in col[val]]\n",
    "    col[val] = a\n",
    "fig = sns.clustermap(data.iloc[:-11][data.columns[np.concatenate((leaves_list(link),[26,27,28,29,30,31,32,33,34,35,36]))]], row_linkage=link, col_colors=col.T, col_cluster=False,figsize=(12,12))\n",
    "fig.ax_col_dendrogram.set_visible(False)\n",
    "fig.savefig(\"../results/cobinding/correlation_onoverlap.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get percentage data between TF and other:\n",
    "        superenhancer, regular, promoter, HMM states*8, cohesin, mediator\n",
    "promoter\n",
    "superenhancer\n",
    "cohesin\n",
    "mediator\n",
    "TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat  = {}\n",
    "for val in merged.columns[8:-12].tolist() + ['activation', 'repression', 'IRF2BP2',\n",
    "    'ATAC', 'MED1', 'SMC1', 'CTCF', 'promoters', 'super_enhancer']:\n",
    "    w = merged[merged[val]!=0]\n",
    "    dat[val] = []\n",
    "    for i in range(1,9):\n",
    "        dat[val].append(len(w[w['HMM_states']==i])/len(w))\n",
    "    for i in ['regular_enhancer','MED1','SMC1','CTCF','promoters','super_enhancer']:\n",
    "        dat[val].append(len(w[w[i]!=0])/len(w))\n",
    "dat = pd.DataFrame(data=dat,index= ['state_'+ str(i) for i in range(1,9)] + ['regular_enhancer','mediator','cohesin','CTCF','promoters','superenhancer']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "# just overlap here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig, ax = plt.subplots(figsize=(10,10)) \n",
    "ax = sns.heatmap(dat,ax=ax)\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.set_ticks([0, .2, .4, .6,.8,1.0])\n",
    "cbar.set_ticklabels(['0%', '20%', '40%', '60%', '80%', '100%'])\n",
    "plt.xticks(rotation=40,ha='left')\n",
    "fig.savefig(\"../results/cobinding/percentage_overlap.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,9):\n",
    "    merged['state_'+str(i)] = (merged.HMM_states==i).astype(float)\n",
    "merged = merged.drop(columns=['HMM_states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap, _, enrichment  = chiphelper.computePairwiseOverlap(merged, norm=False,docorrelation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment = enrichment.replace(-np.inf,-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.clustermap(enrichment,figsize=(12,12), vmin=-7, cmap='RdBu_r')\n",
    "fig.ax_col_dendrogram.set_visible(False)\n",
    "fig.savefig(\"../results/cobinding/enrichment_all.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## TODO\n",
    "\n",
    "### plots during merge\n",
    "\n",
    "- plot a histogram (bincount) of the signal for each peaks:\n",
    "    - peaks in A, B\n",
    "    - unique peaks in A, B\n",
    "    - peaks in merged version (avg)\n",
    "    - scatter plot matrix of signal correlation between 1to1 for all\n",
    "- print average size in unique vs overlap peaks\n",
    "- ratios of unique peaks to total peaks for each TF\n",
    "\n",
    "### plots after merge\n",
    "\n",
    "- create a correlation plot on 1to1 overlap only.\n",
    "- histogram of number of peaks per amount of TF cobound\n",
    "- create a correlation matrix only on A's peakset\n",
    "- create a normalized overlap matrix (given the number of peaks and total peakset, what is the expected overlap and how far away are we from it) z-score norm\n",
    "- create a clustermap over peaks\n",
    "\n",
    "\n",
    "\n",
    "### improving merge\n",
    "\n",
    "- analyse only when peak is supported by two replicates\n",
    "- remove GSE1 and CDK13 from cobinding matrix\n",
    "- do quantile normalization over the signals (after setting up the zeroes)\n",
    "- removing bad chips:\n",
    "    - look, when badchip only does not correlate with anything else..\n",
    "- do log2+1 transform\n",
    "\n",
    "  \n",
    "### peak enrichment\n",
    "- **use chromHMM\n",
    "    - use the Chipseq data we have (RNApol2, CTCF...)\n",
    "- filter weird enrichments (not in H3k27ac? in H4me3..)\n",
    "- make super enhancer enrichment from superenhancer matrix\n",
    "- enrichment in promoter super enhancer other enhancers\n",
    "- **merge the clusters and display enrichment of each (in TF and other marks)\n",
    "\n",
    "\n",
    "### Next step:\n",
    "\n",
    "- do cobinding based on gene targeted from ABC-model and merge the same way as before (mean value); merge enrichments as well\n",
    "- look at data targetting CRC members\n",
    "- look for enrichment at the gene level (from gene annotations)\n",
    "- **compute/refine binding patterns\n",
    "    - use MEME\n",
    "    - motif enrichment in each merged peak set for each TF. do we see the right motifs to be enriched?\n",
    "    - motif enrichment in cobinding peak set.\n",
    "    - use DeepBind\n",
    "- **look for difference in binding patterns to the litterature (db of binding patterns)\n",
    "- ** from clusters, what type of binding patterns do we see in MV411?\n",
    "    - all of them are here?\n",
    "    - some of them. hypothesis 1: the other come randomly into a TAD. only the bound subset is important. we need to look at the binding of this subset only. because here is the binding code\n",
    "    - randomly? after analysis of the enrichment of the genesets bound by the same set of TF we don't see much info.. hypothesis 1: \n",
    "- look for predictability of RNP expression change based on bound genes\n",
    "    - do we see genes with opposite effects? \n",
    "    - can it be explained by the set of co-bound TFs?\n",
    "- do dependency/expression prediction from all gene level features\n",
    "    - look for most explanatory regressors\n",
    "- repeat the process across all samples with H3K27ac+RNAseq data we have.\n",
    "    - call mutations from H3k27ac data\n",
    "    - MEME analysis of likely bound TFs, except if TF is not expressed\n",
    "    - compute enrichments\n",
    "    - from same gene assignements, as found on the general consensus peak set, can we find good dependency/expression prediction\n",
    "- does location\n",
    "    \n",
    "### questions:\n",
    "\n",
    "- how did andrew defined significant peaks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clustering cobinding signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = np.random.choice(merged.index,5000)\n",
    "viridis = cm.get_cmap('viridis', 256)\n",
    "data = merged[merged.columns[-12:]]\n",
    "for val in data.columns[:-4]:\n",
    "    data[val] =stats.zscore(np.log2(1+data[val]))\n",
    "    data[val] = (((data[val] -data[val].min())/ (data[val].max()))*256).astype(int)\n",
    "#print(data['HMM_states'])\n",
    "data = data.loc[rand]\n",
    "for val in data.columns:\n",
    "    a = [viridis(v) for v in data[val]]\n",
    "    data[val] = a\n",
    "data['HMM_states'] = [statetocol[i] for i in data['HMM_states']]\n",
    "data = data.rename(columns={'SMC1':'cohesin','MED1':'mediator','ATAC':'open regions'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(merged.columns[8:-4])\n",
    "cols.remove('PU1')\n",
    "data = stats.zscore(merged[cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = np.random.choice(merged.index,40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(merged.columns[8:-4])\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.cluster.OPTICS.html#sklearn.cluster.OPTICS\n",
    "groups = OPTICS(min_samples=200,n_jobs=8).fit_predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans\n",
    "kmean = KMeans(n_clusters=14,n_jobs=8)\n",
    "groups = kmean.fit_predict(data)\n",
    "centroid = kmean.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig, ax = plt.subplots(figsize=(10,10)) \n",
    "sns.heatmap(pd.DataFrame(centroid,columns=cols).T,vmax=10,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroups = groups[rand]\n",
    "sorting = np.argsort(subgroups)\n",
    "\n",
    "viridis = cm.get_cmap('viridis', len(set(groups)))\n",
    "colors = [viridis(i) for i in subgroups[sorting]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors[-400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.clustermap(np.log2(1.01+merged[cols].iloc[rand].iloc[sorting].T), vmin=0,vmax=3,figsize=(20,15),z_score=0,col_cluster=False,col_colors=colors, xticklabels=False)\n",
    "fig.ax_col_dendrogram.set_visible(False)\n",
    "fig.savefig('../temp/clustermap_cobinding_kmeans_clustered.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot TSNE density map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = (data - data.min(0))/data.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_data = TSNE(2,10,verbose=10,n_iter=1500).fit_transform(scaled_data[rand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(red_data[:,0], red_data[:,1], shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.bigScatter(red_data,binsize=2,showpoint=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SOMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the library\n",
    "import SimpSOM as sps\n",
    "\n",
    "#Build a network 20x20 with a weights format taken from the raw_data and activate Periodic Boundary Conditions. \n",
    "net = sps.somNet(20,20, data, PBC=True)\n",
    "\n",
    "#Train the network for 10000 epochs and with initial learning rate of 0.01. \n",
    "net.train(0.01, 10000)\n",
    "\n",
    "#Save the weights to file\n",
    "net.save('cobinding_SOMweights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=9\n",
    "#Print a map of the network nodes and colour them according to the first feature (column number 0) of the dataset\n",
    "#and then according to the distance between each node and its neighbours.\n",
    "print(merged.columns[col])\n",
    "net.nodes_graph(colnum=col)\n",
    "net.diff_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project the datapoints on the new 2D network map.\n",
    "net.project(merged[merged.columns[8:]].values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster the datapoints according to the Quality Threshold algorithm.\n",
    "clusts = net.cluster(merged[merged.columns[8:]].values, type='DBSCAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing Motif analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## computing motif across the open region of the genome of MV411 from ATACseq with MEME.CentriMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What are the motifs enriched for each cluster groups in the conscensus peak set? using MEME.centrimo (SOM group, DBSCAN group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do we have better correlation if we remove cobinding event that don't have a related motif?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gff2bed < ../../data/MEME/merged/fimo.gff > ../../data/MEME/merged/fimo.gff.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ZEB2',\n",
    " 'MYBL2',\n",
    " 'ZMYND8',\n",
    " 'IKZF1',\n",
    " 'SP1',\n",
    " 'RUNX1',\n",
    " 'PU1_FLAG',\n",
    " 'LDB1',\n",
    " 'IRF8',\n",
    " 'CDK13',\n",
    " 'GATA2',\n",
    " 'GFI1',\n",
    " 'CEBPA',\n",
    " 'MYC',\n",
    " 'LMO2',\n",
    " 'RUNX2',\n",
    " 'FOXP1',\n",
    " 'MYB',\n",
    " 'ETV6',\n",
    " 'MAX',\n",
    " 'MEIS1',\n",
    " 'FLI1',\n",
    " 'LYL1',\n",
    " 'MEF2D_FLAG',\n",
    " 'ELF2']\n",
    "rename = {'MEF2D_FLAG':'MEF2D','MYBL2':'MYBB',\"PU1\":'SPI1','PU1_FLAG':'SPI1'}\n",
    "# TODO: find ZEB2, ZMYND8, LMO2, LDB1, CDK13 motifs\n",
    "\n",
    "for k, val in rename.items():\n",
    "     if k in cols:\n",
    "        cols.remove(k)\n",
    "        cols.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What are the motifs of our CRC members in ATACseq but not in our matrix\n",
    "merged_motif = pd.read_csv('../../data/MEME/merged/fimo.gff.bed', sep='\\t',skiprows=0,index_col=None, names=['pos',\"fimo\", \"nucleotide_motif\",\"relStart\",\"relEnd\",\"pval\",\"strand\",\".\",\"data\"])\n",
    "\n",
    "merged_motif['tf']=[i[5:].split('_HUMAN')[0] for i in merged_motif.data]\n",
    "merged_motif = merged_motif[merged_motif.tf.isin(cols)]\n",
    "merged_motif['chr'] = [i.split(':')[0][3:] for i in merged_motif.index]\n",
    "merged_motif['start'] = [i.split(':')[1].split('-')[0] for i in merged_motif.index]\n",
    "merged_motif['end'] = [i.split(':')[1].split('-')[1] for i in merged_motif.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_motif['end'] = [i.split(':')[1].split('-')[1] for i in merged_motif.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what enrichment do we have in each group? what enrichment do we have for each ChipSeq?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## computing predicted motif for each TF from Chip data MEME-Chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## comparing with the litterature using MEME.tomtom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading motifs from "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### based on closest expressed gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiphelper.AssignToClosestExpressed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### recompute cobinding based on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## redo the plots. do we get better plots?/correlations?..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### based on the ABC model\n",
    "\n",
    "![](images/ABCtitle.png)\n",
    "\n",
    "They tested a new model based on and validated by CRISPRi-FlowFISH which is basically able to find enhancer mapping to genes. \n",
    "They used it to compute their model's Accuracy and found a 70% accuracy compared to less than 50% for closest expressed gene. \n",
    "\n",
    "Way to integrate our HiC data (need ATAC-seq like data as well, but openly available) \n",
    "\n",
    "\n",
    "![](images/ABCmodel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Helper.scatter(TSNE(2,5).fit_transform(data.T), labels=zones.columns[11:],colors=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### recompute cobinding based on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### redo the plots. do we get better looking plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### compare presence of CTCF and transcription of linked RNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a linear model to with marks and cobinding data + cobinding motifs + expression of cobound proteins + expression , can we predict expression/dependenccy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do the same on closest expressed gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do this prediction on each enhancer.what is the best predicting enhancer? do that correlate with ABC model data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do we get, for some gene, better single enhancer prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what are the gene sets enriched in each clusters?? (based on TF cobinding or based on TF cobinding + )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## can we predict RNP data (setting this TF to zero and lookingg at expected RNA change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if we add RNP data, can we increase our model's prediction? (we have expression change and we set all RNPed-TF values to 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### to predict remaining X% RNA expression\n",
    "### to predict remaining X TFs RNP\n",
    "### to predict regular RNA expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## same thing with filtering base on motif presence (actual DNA binding)\n",
    "## same thing with closest expressed gene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compare data with other labs (H3K27, HiC..)\n",
    "\n",
    "we need to redo everything for similar normal cell type, getting TFs based on the CRC (find it with CRCmapper or on litterature)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "372px",
    "left": "78px",
    "top": "111.6px",
    "width": "229.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
